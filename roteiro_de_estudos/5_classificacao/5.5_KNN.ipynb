{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1940e1",
   "metadata": {},
   "source": [
    "# 5.5 - K-Nearest Neighbors\n",
    "\n",
    "Em KNN, K é o número de vizinhos mais próximos. O número de vizinhos é o principal fator decisivo. K é geralmente um número ímpar se o número de classes for 2. Quando K = 1, o algoritmo é conhecido como o algoritmo do vizinho mais próximo. Este é o caso mais simples. Suponha que P1 seja o ponto para o qual o rótulo precisa prever. Primeiro, você encontra o ponto mais próximo de P1 e, em seguida, o rótulo do ponto mais próximo atribuído a P1.\n",
    "\n",
    "![fig_1](https://i.ibb.co/ysBPQ9x/boosting-1-drawio-2.png)\n",
    "\n",
    "\n",
    "Suponha que P1 seja o ponto para o qual o rótulo precisa prever. Primeiro, você encontra o ponto k mais próximo de P1 e, a seguir, classifica os pontos pela maioria dos votos de seus k vizinhos. Cada objeto vota em sua classe e a classe com mais votos é considerada a previsão. Para encontrar os pontos semelhantes mais próximos, você encontra a distância entre os pontos usando medidas de distância como distância euclidiana, distância de Hamming, distância de Manhattan e distância de Minkowski. KNN tem as seguintes etapas básicas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d61adf",
   "metadata": {},
   "source": [
    "![fig_2](https://i.ibb.co/N6FBbPK/boosting-1-drawio-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf19f1",
   "metadata": {},
   "source": [
    "![fig_3](https://i.ibb.co/QKVrQfz/boosting-1-drawio-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601e343",
   "metadata": {},
   "source": [
    "![fig_4](https://i.ibb.co/dJzX0mL/boosting-1-drawio-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9f00f",
   "metadata": {},
   "source": [
    "## Como você decide o número de vizinhos em KNN?\n",
    "\n",
    "A pesquisa mostrou que nenhum número ótimo de vizinhos se adequa a todos os tipos de conjuntos de dados. Cada conjunto de dados tem seus próprios requisitos. No caso de um pequeno número de vizinhos, o ruído terá uma influência maior no resultado, e um grande número de vizinhos o torna computacionalmente caro. A pesquisa também mostrou que uma pequena quantidade de vizinhos é o ajuste mais flexível, que terá baixa tendência, mas alta variância, e um grande número de vizinhos terá um limite de decisão mais suave, o que significa menor variação, mas maior tendência.\n",
    "\n",
    "Geralmente, os cientistas de dados escolhem um número ímpar se o número de classes for par. Você também pode verificar gerando o modelo em diferentes valores de ke verificar seu desempenho. Você também pode tentar o método de Elbow aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668088c0",
   "metadata": {},
   "source": [
    "![fig_5](https://i.ibb.co/sj0kHBb/boosting-1-drawio-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e097f2",
   "metadata": {},
   "source": [
    "## Em Python\n",
    "\n",
    "Definindo Conjunto de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c035da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "# Second Feature\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "# Label or target varible\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d943f",
   "metadata": {},
   "source": [
    "Codificando os dados das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "989db1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "weather_encoded=le.fit_transform(weather)\n",
    "print(weather_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83162814",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_encoded=le.fit_transform(temp)\n",
    "label=le.fit_transform(play)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d5f45",
   "metadata": {},
   "source": [
    "Combinando os recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2ca644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(zip(weather_encoded,temp_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed729df6",
   "metadata": {},
   "source": [
    "Gerando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca815fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "model.fit(features,label)\n",
    "\n",
    "predicted= model.predict([[0,2]])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540225c",
   "metadata": {},
   "source": [
    "### Agora um exemplo com KNN usando multiplos rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cfc1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2930ff2",
   "metadata": {},
   "source": [
    "Explorando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4357dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292b4953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f209506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(wine.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72415803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "print(wine.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1934f63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "print(wine.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512fc0e",
   "metadata": {},
   "source": [
    "Dividindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67211115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f7375",
   "metadata": {},
   "source": [
    "**Criando um modelo com K = 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b1e935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54c35f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f9d47",
   "metadata": {},
   "source": [
    "**Criando um modelo com k=7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e15952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bff6fa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85253e0",
   "metadata": {},
   "source": [
    "## Vantagens\n",
    "\n",
    "A fase de treinamento da classificação de K-neighbor mais próximo é muito mais rápida em comparação com outros algoritmos de classificação. Não há necessidade de treinar um modelo para generalização. É por isso que KNN é conhecido como o algoritmo de aprendizagem simples e baseado em instância. KNN pode ser útil no caso de dados não lineares. Pode ser usado com o problema de regressão. O valor de saída do objeto é calculado pela média do valor de k vizinhos mais próximos.\n",
    "\n",
    "## Desvantagens\n",
    "\n",
    "A fase de teste da classificação de K-neighbor mais próximo é mais lenta e mais cara em termos de tempo e memória. Requer grande memória para armazenar todo o conjunto de dados de treinamento para previsão. KNN requer escalonamento de dados porque KNN usa a distância euclidiana entre dois pontos de dados para encontrar os vizinhos mais próximos. A distância euclidiana é sensível às magnitudes. Os recursos com altas magnitudes terão mais peso do que os recursos com baixas magnitudes. KNN também não é adequado para grandes dados dimensionais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
